{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees\n",
    "\n",
    "In this jupyter notebook, we'll explore building decision tree models considering two approaches: \n",
    "1. the ``scikit-learn`` python machine learning toolkit _(it's pronounced sy-kit)_\n",
    "2. by hand, motivated by Chapter 17 in the Grus textbook.\n",
    "\n",
    "We'll see that while ``scikit-learn`` is very popular and is being actively developed, there are still a number of nice data science features missing from the module (such as the pruning of trees to avoid overfitting).\n",
    "\n",
    "While we're able to view the source of ``scikit-learn`` packages, quickly and correctly understanding the code is a differet story. We'll run into errors if we provide ill-formed funtion calls to the scikit API, and debugging will be a challenge.\n",
    "\n",
    "There's a tradeoff between using the scikit toolkit and writing your own code.\n",
    "\n",
    "Much of the following code utilizes the ``pandas`` library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Links\n",
    "\n",
    "* http://scikit-learn.org/ The current stable version is 0.20. I had to update my Anaconda from 0.17 to 0.20 -- there are some differences in the decision tree api between these two versions. Further, when googling after running into problems, you'll have to navigated between not only python2 and python3 code, but also the version of scikit. Ugh! Real programmer problems!\n",
    "* http://pandas.pydata.org/ Pandas module documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data: Iris\n",
    "\n",
    "We'll use the iris data set again in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though we saw that the iris dataset has an extra blank line at the end, pandas opens it just fine. I specify the column names because the data file doesn't have a header row. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "print(\"Pandas version: \", pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
    "\n",
    "df = pd.read_csv(url, names=['sepal-width', 'sepal-length', 'petal-width', 'petal-length', 'species'])\n",
    "print(\"Dimensions of dataframe: \", df.shape)\n",
    "print(\"Number of rows: \", len(df))\n",
    "print(\"Number of colums: \", len(df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration\n",
    "\n",
    "Displaying the beginning and ending rows of the dataset to veryify that everything seems to be correctly loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class Value Counts\n",
    "\n",
    "What are the different class values? How can we automatically get this information using pandas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['species'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['species'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Experiments\n",
    "\n",
    "Some questions that we want to explore:\n",
    "* What decision tree induction algorithm is used in ``scikit-learn``: ID3, C4.5, CART, something else?\n",
    "* How are the features converted from continuous to categorical -- binning? some other way?\n",
    "* Are there different \"hyperparameters\" we can try?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scikit-learn\n",
    "\n",
    "`sklearn` is the name of the scikit-learn package in Python.\n",
    "\n",
    "It should already be installed with the anaconda environment (but you want to make sure it's updated)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install scikit-learn --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "print(\"scikit-learn version: \", sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting to a feature matrix and target vector\n",
    "\n",
    "scikit-learn requires data to be properly formatted, in the layout of a:\n",
    "1. feature matrix \"X\" ( _m features x n_ records )\n",
    "2. target vector \"y\" ( _n_ class values)\n",
    "\n",
    "Below, we extract the feature matrix and target array from the `pandas` dataframe, using `pandas` DataFrame operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('species', axis=1)\n",
    "y = df['species']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verifying the shape dimensions of the extracted feature matrix and target vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indexing into the feature matrix and target vector: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['sepal-width'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(df))\n",
    "print(type(X))\n",
    "print(type(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Induction\n",
    "\n",
    "API: http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier\n",
    "\n",
    "Note there are lots of parameters that we can specify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.tree\n",
    "\n",
    "model1 = sklearn.tree.DecisionTreeClassifier()\n",
    "model1 = model1.fit(X, y)   # naming the decision tree 'model1', for lack of a better name\n",
    "model1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the learned tree model\n",
    "\n",
    "_(Ugly! two installations needed)_\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html#sklearn.tree.export_graphviz\n",
    "\n",
    "This took me some time to get working on my home Mac laptop. \n",
    "\n",
    "1. https://pypi.org/project/graphviz/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. As specified on the pypi graphviz documentation: \"To render the generated DOT source code, you also need to install Graphviz. Make sure that the directory containing the dot executable is on your systemsâ€™ path.\n",
    "https://www.graphviz.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!brew install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.columns)\n",
    "print(y.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = sklearn.tree.export_graphviz(model1, out_file=None,\n",
    "                         feature_names=X.columns,  \n",
    "                         class_names=y.unique(),  \n",
    "                         filled=True, rounded=True,  \n",
    "                         special_characters=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graphviz.Source(dot_data)  \n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running an instance through the learned decision tree model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get an instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lastrow = X.iloc[149]\n",
    "\n",
    "print(lastrow)          # the last row of the feature matrix (minus the target class) of the dataset\n",
    "type(lastrow)           # it's a Series object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sklearn` complains if we give it a pandas dataframe or a pandas series. It likes receiving a 2D numpy array, instead. a 1D numpy array won't work.\n",
    "\n",
    "`reshape` will convert data into a 2D numpy array.\n",
    "* `.reshape(1,-1)` is used for a single row dataframe (an instance/observation)\n",
    "* `.reshape(-1,1)` is used for a single column dataframe (an attribute/feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lastrow)\n",
    "print(type(lastrow))          # Series\n",
    "      \n",
    "print(\"------------\")\n",
    "      \n",
    "print(lastrow.values)\n",
    "print(type(lastrow.values))   # 1D numpy array\n",
    "\n",
    "print(\"------------\")\n",
    "\n",
    "print(lastrow.values.reshape(1,-1))    # 2D array\n",
    "print(type(lastrow.values.reshape(1,-1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making a Prediction on the Test Instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can pass a row (one that is represented as a 2D array) to the model for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model1.predict(lastrow.values.reshape(1,-1))\n",
    "predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Path\n",
    "\n",
    "There is a `decision_path` method (new in version 0.18) that outputs how the testing instance traveled from the root node to a leaf.\n",
    "\n",
    "There's limited documentation on it?\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier.decision_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model1.decision_path(lastrow.values.reshape(1,-1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Data into a Training Set and Testing Set\n",
    "\n",
    "Note that this code is also different between <= v0.17 and the current stable version.\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "\n",
    "There are four arguments that we'll specify, as commented below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,    # predictive features\n",
    "                                                    y,      # target column\n",
    "                                                    test_size=0.33,    # 33% of dataset will be set aside for test set\n",
    "                                                    random_state=42)   # for reproducibility\n",
    "print(\"Size of training: \", len(X_train))\n",
    "print(X_train)\n",
    "print(\"Size of testing: \", len(X_test))\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's interesting to compare the method call using the ``scikit-learn`` module against the Grus text which codes this by hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grus code\n",
    "\n",
    "# TO INSERT....\n",
    "\n",
    "# READ Ch. 17!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running our Model Against the Test Set\n",
    "\n",
    "Use the `.score` method. \n",
    "We're going to pass to it the testing rows, which are divided into:\n",
    "* ``X_test``: the testing features (everything except the target)\n",
    "* ``y_test``: the testing answers (the actual target we hope we predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the 50 testing instances through ``model1`` (which was trained on all 150 instances), and comparing the model's prediction to the actual correct classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "100% accuracy on the _test set_? This seems way too good. This is because `model1` was trained on _all_ data; we really only want it trained on the _training set_.\n",
    "\n",
    "Trying again with a new model: `model2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = sklearn.tree.DecisionTreeClassifier()\n",
    "model2 = model2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training accuracy rate:\", model2.score(X_train, y_train))\n",
    "print(\"Generalized testing accuracy rate:\", model2.score(X_test, y_test))\n",
    "model2.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is fabulous! For academic purposes, let's build a model that is not 100% perfect, but adjusting the training/testing set splits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,    # predictive features\n",
    "                                                    y,    # target column\n",
    "                                                    test_size=0.80,    # 33% of dataset will be set aside for test set\n",
    "                                                    random_state=42)   # for reproducibility\n",
    "print(\"Size of training: \", len(X_train))\n",
    "print(\"Size of testing: \", len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = sklearn.tree.DecisionTreeClassifier()\n",
    "model3 = model3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training accuracy rate:\", model3.score(X_train, y_train))\n",
    "print(\"Generalized testing accuracy rate:\", model3.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = sklearn.tree.export_graphviz(model3, out_file=None,\n",
    "                         feature_names=X.columns,  \n",
    "                         class_names=y.unique(),  \n",
    "                         filled=True, rounded=True,  \n",
    "                         special_characters=True)\n",
    "graph = graphviz.Source(dot_data)  \n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other things to explore\n",
    "\n",
    "There are other interested attributes and methods worth exploring in the `sklearn.tree` module.\n",
    "\n",
    "Examine the documentation. Also try using tab autocomplete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model2.feature_importances_)\n",
    "print(model2.tree_.node_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pruning\n",
    "\n",
    "Quesions to answer:\n",
    "* Does pruning help on the iris tree?\n",
    "* Is pruning automatically performed in the sklearn implementation?\n",
    "\n",
    "From the documentation:\n",
    "\"Decision-tree learners can create over-complex trees that do not generalise the data well. This is called overfitting. Mechanisms such as pruning (not currently supported), setting the minimum number of samples required at a leaf node or setting the maximum depth of the tree are necessary to avoid this problem.\"\n",
    "\n",
    "http://scikit-learn.org/stable/modules/tree.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Methods: Boosting, Bagging, Random Forests\n",
    "\n",
    "See: http://scikit-learn.org/stable/modules/ensemble.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boosting\n",
    "\n",
    "Now supported in latest version! https://scikit-learn.org/stable/modules/ensemble.html#adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = sklearn.ensemble.AdaBoostClassifier(n_estimators=10)\n",
    "model4 = model4.fit(X_train, y_train)\n",
    "model4.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bagging\n",
    "\n",
    "See: http://scikit-learn.org/stable/modules/ensemble.html#bagging-meta-estimator\n",
    "\n",
    "Note that because there is a random aspect to bagging (unless a random seed is used), the bagging evaluation may produce a different result every time it is run, because the decision trees will be different every time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model5 = sklearn.ensemble.BaggingClassifier(sklearn.tree.DecisionTreeClassifier(),\n",
    "                            max_samples=0.5, max_features=0.5)\n",
    "model5 = model5.fit(X_train, y_train)\n",
    "model5.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forests\n",
    "\n",
    "See: http://scikit-learn.org/stable/modules/ensemble.html#forests-of-randomized-trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model6 = sklearn.ensemble.RandomForestClassifier(n_estimators=10)\n",
    "model6 = model6.fit(X_train, y_train)\n",
    "model6.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examining the Misclassifications: What the Model Got Wrong\n",
    "\n",
    "We have our testing set, represented by the dataframes: `X_test` and `y_test`.\n",
    "\n",
    "The below code demos how to:\n",
    "1. index the `y_test` series/dataframe using a row's id\n",
    "2. loop/iterate through the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[109]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, instance in X_test.iterrows():               # get every row from the test set\n",
    "    # print(index, instance['sepal-width'])             # print the index number and sepal-width attribute\n",
    "    predict = model3.predict(instance.values.reshape(1,-1))    # convert the instance row (dataframe/series) into a numpy array, send it through the model\n",
    "    if (predict != y_test[index]):                      # see if the model's prediction matches the true species\n",
    "        print(\"WRONG: \", index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.loc[56]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Regression Trees\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html#sklearn.tree.DecisionTreeRegressor"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
